<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>HBase</title>
    <link>https://hello-world-example.github.io/HBase/</link>
    <description>Recent content on HBase</description>
    <generator>Hugo -- gohugo.io</generator>
    
	<atom:link href="https://hello-world-example.github.io/HBase/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/_sidebar/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/_sidebar/</guid>
      <description> Install  Docker 安装 HBase 单机本地文件系统 Docker 搭建单机 CDH 环境 HBase 配置简介 Port   Cli  hbase shell   Core  RowKey Family Filter _架构简介 压缩和编码 写路径和优化 读路径和优化 LSM Tree   Action  Delete 操作语义 HFile Tool 查看 HFile 如何使用 Bulk Loading YCSB 测试   Opt  _Zookeeper 目录结构    </description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Action/Delete-API/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Action/Delete-API/</guid>
      <description>Delete 操作语义 单独把 Delete 拎出来，是因为 Delete 的 实际效果 与 语义 可能不符，比如常会出现
 本来想删除一个版本的数据，结果删除了一批 删除之后重新写入，虽然操作成功，但是读取不到数据 API 比较类似，很容易搞混，想象中与实际操作区别很大 &amp;hellip;  简介 HBase 支持多版本，即支持向同一个 rowkey:family:qualifier 中写入多个 timestamp 不同的 value。timestamp 不仅可以由服务器根据写入时间生成，也可以由用户指定。尤其是在由用户指定的时候需要更加注意，因为常常会出现后写入数据的 timestamp 比之前写入的数据的 timestamp 还小的情况，即写入一个很久之前数据的情况。
因为存储采用 LSM (Log-Structured Merge Tree) 结构， HBase 的删除操作并不会立即将数据从磁盘上删除，当执行删除操作时，会新插入一条相同的 KeyValue 数据，通过 keytype（如： keytype=Delete）标记删除类型。这意味着数据删除实际上也是一个普通的 Put 追加操作，直到发生 major_compact 操作时，数据才会被真正的从磁盘上删除，删除标记也会从 StoreFile 删除。
hbase shell 数据准备 # 创建一个表，最多可以有 5个 版本 &amp;gt; create &amp;#39;test&amp;#39;, {NAME =&amp;gt; &amp;#39;f&amp;#39;, VERSIONS =&amp;gt; 5} # 插入三条数据，版本分别是 1/2/3 &amp;gt; put &amp;#39;test&amp;#39;, &amp;#39;r1&amp;#39;, &amp;#39;f:c1&amp;#39;, &amp;#39;1&amp;#39;, 1 &amp;gt; put &amp;#39;test&amp;#39;, &amp;#39;r1&amp;#39;, &amp;#39;f:c1&amp;#39;, &amp;#39;2&amp;#39;, 2 &amp;gt; put &amp;#39;test&amp;#39;, &amp;#39;r1&amp;#39;, &amp;#39;f:c1&amp;#39;, &amp;#39;3&amp;#39;, 3 # 查看数据 &amp;gt; scan &amp;#39;test&amp;#39; ROW COLUMN+CELL r1 column=f:c1, timestamp=3, value=3 # 查看所有版本 &amp;gt; scan &amp;#39;test&amp;#39;, { VERSIONS =&amp;gt; 5 } ROW COLUMN+CELL r1 column=f:c1, timestamp=3, value=3 r1 column=f:c1, timestamp=2, value=2 r1 column=f:c1, timestamp=1, value=1 delete  delete &#39;表名&#39;, &#39;行键&#39;, &#39;列&#39; delete &#39;表名&#39;, &#39;行键&#39;, &#39;列&#39;, 时间戳  删除列（的最新版本）  delete &#39;表名&#39;, &#39;行键&#39;, &#39;列&#39;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Action/Hfile-Pretty-Printer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Action/Hfile-Pretty-Printer/</guid>
      <description>通过 “HFile Tool” 查看 HFile文件内容 查看 HFile 内容的文本版本, 你可以使用org.apache.hadoop.hbase.io.hfile.HFile工具。输入以下命令查看使用帮助。
$ hbase org.apache.hadoop.hbase.io.hfile.HFile usage: HFile [-a] [-b] [-e] [-f &amp;lt;arg&amp;gt; | -r &amp;lt;arg&amp;gt;] [-h] [-k] [-m] [-p] [-s] [-v] [-w &amp;lt;arg&amp;gt;] -a,--checkfamily Enable family check -b,--printblocks Print block index meta data -e,--printkey Print keys -f,--file &amp;lt;arg&amp;gt; File to scan. Pass full-path; e.g. hdfs://a:9000/hbase/hbase:meta/12/34 -h,--printblockheaders Print block headers for each block. -k,--checkrow Enable row order check; looks for out-of-order keys -m,--printmeta Print meta data of file -p,--printkv Print key/value pairs -r,--region &amp;lt;arg&amp;gt; Region to scan.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Action/How-To-Use-Hbase-Bulk-Loading/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Action/How-To-Use-Hbase-Bulk-Loading/</guid>
      <description>如何使用 Bulk Loading  原文地址：How-to: Use HBase Bulk Loading, and Why
 Apache HBase 为您提供对大数据的 随机、实时、读/写 访问，如何有效地将数据迁移到到 HBase 呢？ 用户可以尝试通过 客户端API 或使用 MapReduce作业TableOutputFormat输出格式，但这些方法存在一些问题，下面会说到。 HBase bulk loading(批量加载) 功能更易于使用，并且可以更快地插入相同数量的数据
本博客文章将介绍 bulk loading(批量加载) 功能的基本概念，介绍两种使用场景，并展示了两个例子。
Bulk Loading 概述 如果您使用传统方式（API、MapReduce）会有下面这些问题，bulk loading(批量加载) 可能是您的正确选择：
 您需要调整 MemStore 来获取更大的内存。 您需要使用更大的WAL或完全绕过它们。 您的压缩和flush队列数百个。 您的GC失控，因为您的插入数据量很大。 导入数据时，您的延迟超出SLA（Service-Level Agreement，《SRE：Google运维解密》一书中有介绍）  大多数这些症状通常被称为“成长中的痛苦”（growing pains）。使用批量加载可以帮助您避免它们。
在HBase中，bulk loading 是准备和加载HFiles（HBase自己的文件格式）到RegionServers中的过程， 因此绕过了写入路径并完全避免了上述那些问题。此过程与ETL类似，如下所示：
1.从资源中提取数据，通常是文本文件或其他数据库 HBase不管理数据提取这部分过程。 换句话说，你不能通过直接从 MySQL 读取 HFiles 来告诉HBase准备HFile，相反，你必须以自己的方式来完成数据抽取。 例如，您可以在一个表上运行mysqldump并将结果文件上传到HDFS，或者获取您的Apache HTTP日志文件。 无论如何，在下一步之前，您的数据需要上传到 HDFS。
 实际上在本地磁盘也可以，如果数据量一台机器可以承受的话； Hadoop 的 默认文件系统是本地文件系统 &amp;ldquo;fs.defaultFS=file:///&amp;rdquo;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Cli/HBase-Shell/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Cli/HBase-Shell/</guid>
      <description>hbase shell 基础命令 # 进入 ᐅ ./bin/hbase shell # 退出 hbase&amp;gt; exit # 查看帮助 ᐅ ./bin/hbase shell -h # 或 hbase&amp;gt; help hbase&amp;gt; help &amp;#39;group name&amp;#39; hbase&amp;gt; help &amp;#39;command&amp;#39; # Debug 模式 ᐅ ./bin/hbase shell -d # 启动或者关闭 debug 模式 hbase&amp;gt; debug # 查看是否启动 debug 模式 hbase&amp;gt; debug? General ✔️ # status == status &amp;#39;summary&amp;#39; hbase&amp;gt; status 1 active master, 0 backup masters, 1 servers, 0 dead, 2.0000 average load hbase&amp;gt; status &amp;#39;simple&amp;#39; hbase&amp;gt; status &amp;#39;detailed&amp;#39; hbase&amp;gt; status &amp;#39;replication&amp;#39; # 表操作示使用文档 hbase&amp;gt; table_help # hbase&amp;gt; version 1.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Core/Architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Core/Architecture/</guid>
      <description>架构简介 Master Master 可以有多个实现热备，通过 Zookeeper 选举一个为主，其他为备做 Failover。
主要作用有：
 管理 RegionServer 和 其负载均衡 管理和分配 Region  Region Split 时分配新的 Region RegionServer 退出时迁移其 Region 到其他 RegionServer   DDL操作，Namespace 、Table、Family 的增删改 Namespace 、Table、Family 元数据管理 ACL 权限控制  RegionServer   管理 Region
  读写 FS，管理 Table 中的数据
  Client 直连 RegionServer 读写数据，从 Master 中获取元数据，找到 RowKey 所在的 RegionServer
  RegionServer 一般和 HDFS DataNode 在同一台机器上运行，实现数据的本地性
  Region  RowKey 是有序的，HBase 根据 RowKey 来划分和查找 Region  HLog / WAL  WAL(Write Ahead Log) 在早期版本中称为 HLog 默认写操作会先保证将数据写入这个 Log 文件，才会真正更新 MemStore Client 可以通过 put.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Core/Family-Properties/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Core/Family-Properties/</guid>
      <description>HBase 列族配置 创建一个测试表（test），列族名为 f
hbase&amp;gt; create &amp;#39;test&amp;#39;, {NAME =&amp;gt; &amp;#39;f&amp;#39;} 默认属性如下：
hbase&amp;gt; describe &amp;#39;test&amp;#39; { NAME =&amp;gt; &amp;#39;f&amp;#39;, BLOOMFILTER =&amp;gt; &amp;#39;ROW&amp;#39;, VERSIONS =&amp;gt; &amp;#39;1&amp;#39;, MIN_VERSIONS =&amp;gt; &amp;#39;0&amp;#39;, KEEP_DELETED_CELLS =&amp;gt; &amp;#39;FALSE&amp;#39;, DATA_BLOCK_ENCODING =&amp;gt; &amp;#39;NONE&amp;#39;, COMPRESSION =&amp;gt; &amp;#39;NONE&amp;#39;, TTL =&amp;gt; &amp;#39;FOREVER&amp;#39;, BLOCKCACHE =&amp;gt; &amp;#39;true&amp;#39;, BLOCKSIZE =&amp;gt; &amp;#39;65536&amp;#39;, IN_MEMORY =&amp;gt; &amp;#39;false&amp;#39;, REPLICATION_SCOPE =&amp;gt; &amp;#39;0&amp;#39; } 基本属性 BLOOMFILTER(布隆过滤器) 布隆过滤器 可以判断数据不存在，当判断结果存在时，数据可能真的存在，也可能不存在。可选的值有 三个 NONE, ROW (default), ROWCOL。
当开启 布隆过滤器 时，可以判断要查询的数据不存在在表中，从而避免查表。
行级（ROW）布隆过滤器在数据块里检查特定行键是否不存在，列标识符级（ROWCOL）布隆过滤器检查行和列标识符联合体是否不存在。ROWCOL布隆过滤器的开销高于ROW布隆过滤器。
VERSIONS(Cell数据版本) 0.96版本默认是3个， 0.98版本之后是1， 要根据业务来划分，版本是历史记录，版本增多意味空间消耗。
插入数据的时候，版本默认是当前时间；查询的时候可以指定要获取的版本个数 get &#39;test&#39;, &#39;rk1&#39;, { COLUMN =&amp;gt; &#39;f&#39;, VERSIONS =&amp;gt; 100}；</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Core/Filter/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Core/Filter/</guid>
      <description>HBase 内置过滤器简介 HBase 的过滤器可以让我们在查询中添加更多的限制条件 来减少查询得到的数据量，从而帮助用户提高处理表数据的效率。 所有的过滤器都在服务端生效，使被过滤掉的数据不会被传送到客户端。
Filter 的继承结构  Filter  FilterBase  CompareFilter  RowFilter FamilyFilter QualifierFilter ValueFilter DependentColumnFilter   SingleColumnValueFilter  SingleColumnValueExcludeFilter   PrefixFilter PageFilter (*.fiter) KeyOnlyFilter FirstKeyOnlyFilter  FirstKeyValueMatchingQualifiersFilter   InclusiveStopFilter TimestampsFilter ColumnCountGetFilter ColumnPaginationFilter ColumnPrefixFilter RandomRowFilter ColumnRangeFilter MultipleColumnPrefixFilter MultiRowRangeFilter FuzzyRowFilter SkipFilter WhileMatchFilter   FilterList FilterWrapper    CompareFilter CompareFilter 返回匹配的行。
构造函数：
public CompareFilter(final CompareOp compareOp, final ByteArrayComparable comparator) { this.compareOp = compareOp; this.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Core/Port/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Core/Port/</guid>
      <description>常用端口    端口 描述       2181 Zookeeper 端口           8080 HBase REST Port hbase.rest.port    16000 HBase Master hbase.master.port 1.0 之前 60000   16010 HBase Master Web UI port hbase.master.info.port 1.0 之前 60010   16020 HBase RegionServer Port hbase.regionserver.port 1.0 之前 60020   16030 HBase RegionServer Web UI port hbase.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Core/Read-Path/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Core/Read-Path/</guid>
      <description>第二个新功能是全链路 Off-heap，意思就是读写链路数据端到端 Off-heap，减少 java GC 带来的停顿，进一步降低 P999 延迟，提高吞吐。这个功能我们从两方面来实现的：写链路 Off-heap，我们使用在 RPC 层使用 Netty 的 Off-heap ByteBuffer，使用支持 Off-heap 的 Protobuf。同时使用 Off-heap 的 Chunk 来存储 Memstore 中的 KeyValue。
在读链路 Off-heap 方面，使用 Off-heap 的 Bucket Cache，HBase 自己管理内存的，我们从 Bucket Cache 读取数据的时候，先要从 Protobuf 做一次拷贝，因为可能读取的时候，发生内存不够了，再次分配的情况。在读取对 Bucket Cache 进行引用计数，保证读取的时候，内存不会被回收掉，读取时不再需要先拷贝到 heap，对 Bucket Cache 进行了一系列性能优化。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Core/RowKey/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Core/RowKey/</guid>
      <description>Rowkey 设计  Rowkey 是一段二进制码流，最大长度为64KB Rowkey 以字典顺序排序，其方法是，按照字母顺序，或者数字小大顺序，由小到大的形成序列  Rowkey：123,321,2 顺序为: 123,2,321   查找数据的时候，先查找 Rowkey 所在的 Region，然后将求路由到该 Region 获取数据 按单个 Rowkey 检索的效率是很高的，耗时在1毫秒以下  设计原则 避免热点 避免热点首先要了解 Rowkey的排序规则 和 分区分类原理
 RowKey 按照 字典顺序 从小到大，如： 1, 12, 27, 3, 4, 66 如果没有预分区的话，刚开始所有的数据落在一个分区，当分区达到一定的阀值开始分裂，以上数据可能会分裂成 1, 12, 27 和 3, 4, 66 两个分区，每个分区记录 StartKey 和 EndKey， 多个分区会落在不同的机器上，避免热点的目的是为了利用集群的能力 和 减少分裂的次数，而不是操作都落在一台机器上  可以让头几位尽量是随机的而不是规律的产生，从而避免热点，大概有一下几种场景
 自增序列、时间戳 等自增序列  产生的数据类似于 11,12,13,14,15,16 ，假如现在有两个分区  [0,14..): 11,12,13 [14..,无穷):14,15,16 新生成 19,20,21,22 都会落在第二个分区   对于自增序列，可以通过转置的方式  比如对以上序列转置后变为，11,21,31,41,51,61 [0,4.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Core/Wirte-Path/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Core/Wirte-Path/</guid>
      <description>写路径和优化 并发写 </description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Install/Properties/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Install/Properties/</guid>
      <description>HBase 配置简介 获取 HBase 可配置的选项通常有以下方法：
 org.apache.hadoop.hbase.HConstants 常量类 hbase-common-x.x.x.jar 根目录下的 hbase-default.xml 配置文件 HMaster Web UI Configuration: http://localhost:16010/conf  Core / Install 以下是让 HBase 启动和运行的重要配置
hbase.tmp.dir 本地文件系统上的临时目录
默认 ${java.io.tmpdir}/hbase-${user.name}（/tmp/hbase-${user.name}）, 系统重启会自动清除
hbase.rootdir HBase 的数据保存目录。 如果是本地文件系统，必须是全路径；如果是 HDFS hdfs://namenode.example.org:9000/hbase
默认 ${hbase.tmp.dir}/hbase
hbase.fs.tmp.dir 默认文件系统（HDFS） 上用于暂存临时数据的目录
默认 /user/${user.name}/hbase-staging
hbase.bulkload.staging.dir 默认文件系统（HDFS）中的暂存批量加载临时数据目录
默认 ${hbase.fs.tmp.dir}
hbase.cluster.distributed 是否在集群模式下运行。 独立模式下的值为false，分布式模式下为true。 如果为false，将在一个JVM中一起运行所有HBase和ZooKeeper守护进程
默认 false
hbase.zookeeper.quorum 用逗号分隔的 ZooKeeper 服务器的列表。 例如host1.mydomain.com，host2.mydomain.com，host3.mydomain.com。 默认情况下，独立模式和伪分布式模式 下为localhost。 对于完全分布式模式，应该将其设置为ZooKeeper服务器的完整列表。 如果对hbase-env.sh中HBASE_MANAGES_ZK的设为true，HBase 会把 ZooKeeper 作为群集的一部分 启动（/停止）。 在客户端，常与hbase.zookeeper.clientPort（Zookeeper 端口）配置放在一起使用，并将其作为connectString参数传递给zookeeper构造函数
默认 localhost
Master hbase.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Install/Stand-Alone-By-Docker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Install/Stand-Alone-By-Docker/</guid>
      <description>Docker 安装 HBase  端口描述详见 Port
可选
-p 8084:8080
-p 8085:8085
-p 9090:9090
-p 9095:9095 \
 $ docker run -d \  -p 2181:2181 \  -p 8084:8080 \  -p 8085:8085 \  -p 16000:16000 \  -p 16010:16010 \  -p 16020:16020 \  -p 16030:16030 \  --name hbase \  harisekhon/hbase # 启动 HBase REST API $ docker exec -it hbase bash # 不加端口的情况下，端口默认为8080 $$ hbase-daemon.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Install/Stand-Alone-CDH-Docker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Install/Stand-Alone-CDH-Docker/</guid>
      <description>Docker 搭建单机 CDH 环境    QuickStarts for CDH 5.13 官方下载地址
  Cloudera Docker Container 官方文档
  cloudera/quickstart 仓库
   使用 Docker 安装   MAC 设置 Docker 内存 端口描述详见 Port   # 镜像有 5G， 下载比较慢 # wget https://downloads.cloudera.com/demo_vm/docker/cloudera-quickstart-vm-5.13.0-0-beta-docker.tar.gz ᐅ docker pull cloudera/quickstart # 启动容器 ᐅ docker run -d \ 	--hostname=quickstart.cloudera \ 	--privileged=true \ 	--name=cdh-5.13 \ 	-p 81:80 \ 	-p 2181:2181 \ 	-p 9092:9092 \ 	-p 60010:60010 \ 	-p 60000:60000 \ 	-p 8888:8888 \ 	-p 7180:7180 \ 	cloudera/quickstart bash -c &amp;#34;while true; do echo noting; sleep 1; done&amp;#34; # /usr/bin/docker-quickstart # 进入容器 ᐅ docker exec -it cdh-5.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Install/Stand-Alone-Local-File/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Install/Stand-Alone-Local-File/</guid>
      <description>单机本地文件系统 # 下载 wget http://mirrors.hust.edu.cn/apache/hbase/stable/hbase-1.2.6-bin.tar.gz vim hbase-1.2.6/conf/hbase-site.xml # 新增 # &amp;lt;property&amp;gt; # &amp;lt;name&amp;gt;hbase.rootdir&amp;lt;/name&amp;gt; # &amp;lt;value&amp;gt;file:///opt/data/hbase&amp;lt;/value&amp;gt; # &amp;lt;/property&amp;gt; # # 如果 hbase-env.sh 中 export HBASE_MANAGES_ZK=true 设置true，最好指定 Zookeeper 的数据路劲 # &amp;lt;property&amp;gt; # &amp;lt;name&amp;gt;hbase.zookeeper.property.dataDir&amp;lt;/name&amp;gt; # &amp;lt;value&amp;gt;/opt/data/hbase-zookeeper&amp;lt;/value&amp;gt; # &amp;lt;/property&amp;gt; # # 如果 hbase-env.sh 中 export HBASE_MANAGES_ZK=false 设置false，需要再加入以下配置 # &amp;lt;property&amp;gt; # &amp;lt;name&amp;gt;hbase.cluster.distributed&amp;lt;/name&amp;gt; # &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt; # &amp;lt;/property&amp;gt; vim hbase-1.2.6/conf/hbase-env.sh # 修改 JAVA_HOME， 去掉前面的 #， # export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/ # 修改 HBASE_CLASSPATH ，去掉前面的 # # export HBASE_CLASSPATH=/opt/websuite/hbase-1.2.6 # 默认是 true ，如果使用 外部 Zookeeper ，设置为 false 即可 # export HBASE_MANAGES_ZK=true # 启动 Hbase .</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/todo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/todo/</guid>
      <description>TODO  HBase Zookeeper 目录结构 HFile 存储格式 Block Cache 和 MemStore MOB 写路径 写路径 hbase pe 新版压测工具： https://blog.csdn.net/shudaqi2010/article/details/89760946  </description>
    </item>
    
  </channel>
</rss>