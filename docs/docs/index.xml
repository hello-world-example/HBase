<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docs on HBase</title>
    <link>https://hello-world-example.github.io/HBase/docs/</link>
    <description>Recent content in Docs on HBase</description>
    <generator>Hugo -- gohugo.io</generator>
    
	<atom:link href="https://hello-world-example.github.io/HBase/docs/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Action/Hfile-Pretty-Printer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Action/Hfile-Pretty-Printer/</guid>
      <description>通过 “HFile Tool” 查看 HFile文件内容 查看 HFile 内容的文本版本, 你可以使用org.apache.hadoop.hbase.io.hfile.HFile工具。输入以下命令查看使用帮助。
$ hbase org.apache.hadoop.hbase.io.hfile.HFile usage: HFile [-a] [-b] [-e] [-f &amp;lt;arg&amp;gt; | -r &amp;lt;arg&amp;gt;] [-h] [-k] [-m] [-p] [-s] [-v] [-w &amp;lt;arg&amp;gt;] -a,--checkfamily Enable family check -b,--printblocks Print block index meta data -e,--printkey Print keys -f,--file &amp;lt;arg&amp;gt; File to scan. Pass full-path; e.g. hdfs://a:9000/hbase/hbase:meta/12/34 -h,--printblockheaders Print block headers for each block. -k,--checkrow Enable row order check; looks for out-of-order keys -m,--printmeta Print meta data of file -p,--printkv Print key/value pairs -r,--region &amp;lt;arg&amp;gt; Region to scan.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Action/How-To-Use-Hbase-Bulk-Loading/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Action/How-To-Use-Hbase-Bulk-Loading/</guid>
      <description>如何使用 Bulk Loading  原文地址：How-to: Use HBase Bulk Loading, and Why
 Apache HBase 为您提供对大数据的 随机、实时、读/写 访问，如何有效地将数据迁移到到 HBase 呢？ 用户可以尝试通过 客户端API 或使用 MapReduce作业TableOutputFormat输出格式，但这些方法存在一些问题，下面会说到。 HBase bulk loading(批量加载) 功能更易于使用，并且可以更快地插入相同数量的数据
本博客文章将介绍 bulk loading(批量加载) 功能的基本概念，介绍两种使用场景，并展示了两个例子。
 Bulk Loading 概述 如果您使用传统方式（API、MapReduce）会有下面这些问题，bulk loading(批量加载) 可能是您的正确选择：
 您需要调整 MemStore 来获取更大的内存。 您需要使用更大的WAL或完全绕过它们。 您的压缩和flush队列数百个。 您的GC失控，因为您的插入数据量很大。 导入数据时，您的延迟超出SLA（Service-Level Agreement，《SRE：Google运维解密》一书中有介绍）  大多数这些症状通常被称为“成长中的痛苦”（growing pains）。使用批量加载可以帮助您避免它们。
在HBase中，bulk loading 是准备和加载HFiles（HBase自己的文件格式）到RegionServers中的过程， 因此绕过了写入路径并完全避免了上述那些问题。此过程与ETL类似，如下所示：
1.从资源中提取数据，通常是文本文件或其他数据库 HBase不管理数据提取这部分过程。 换句话说，你不能通过直接从 MySQL 读取 HFiles 来告诉HBase准备HFile，相反，你必须以自己的方式来完成数据抽取。 例如，您可以在一个表上运行mysqldump并将结果文件上传到HDFS，或者获取您的Apache HTTP日志文件。 无论如何，在下一步之前，您的数据需要上传到 HDFS。
 实际上在本地磁盘也可以，如果数据量一台机器可以承受的话； Hadoop 的 默认文件系统是本地文件系统 &amp;ldquo;fs.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Cli/HBase-Shell/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Cli/HBase-Shell/</guid>
      <description>hbase shell 基础命令 # 进入 ᐅ ./bin/hbase shell # 退出 hbase&amp;gt; exit # 查看帮助 ᐅ ./bin/hbase shell -h # 或 hbase&amp;gt; help hbase&amp;gt; help &amp;#39;group name&amp;#39; hbase&amp;gt; help &amp;#39;command&amp;#39; # Debug 模式 ᐅ ./bin/hbase shell -d # 启动或者关闭 debug 模式 hbase&amp;gt; debug # 查看是否启动 debug 模式 hbase&amp;gt; debug? General ✔️ # status == status &amp;#39;summary&amp;#39; hbase&amp;gt; status 1 active master, 0 backup masters, 1 servers, 0 dead, 2.0000 average load hbase&amp;gt; status &amp;#39;simple&amp;#39; hbase&amp;gt; status &amp;#39;detailed&amp;#39; hbase&amp;gt; status &amp;#39;replication&amp;#39; # 表操作示使用文档 hbase&amp;gt; table_help # hbase&amp;gt; version 1.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Core/Family-Properties/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Core/Family-Properties/</guid>
      <description>HBase 列族配置 创建一个测试表（test），列族名为 f
hbase&amp;gt; create &amp;#39;test&amp;#39;, {NAME =&amp;gt; &amp;#39;f&amp;#39;} 默认属性如下：
hbase&amp;gt; describe &amp;#39;test&amp;#39; { NAME =&amp;gt; &amp;#39;f&amp;#39;, BLOOMFILTER =&amp;gt; &amp;#39;ROW&amp;#39;, VERSIONS =&amp;gt; &amp;#39;1&amp;#39;, MIN_VERSIONS =&amp;gt; &amp;#39;0&amp;#39;, KEEP_DELETED_CELLS =&amp;gt; &amp;#39;FALSE&amp;#39;, DATA_BLOCK_ENCODING =&amp;gt; &amp;#39;NONE&amp;#39;, COMPRESSION =&amp;gt; &amp;#39;NONE&amp;#39;, TTL =&amp;gt; &amp;#39;FOREVER&amp;#39;, BLOCKCACHE =&amp;gt; &amp;#39;true&amp;#39;, BLOCKSIZE =&amp;gt; &amp;#39;65536&amp;#39;, IN_MEMORY =&amp;gt; &amp;#39;false&amp;#39;, REPLICATION_SCOPE =&amp;gt; &amp;#39;0&amp;#39; }  基本属性 BLOOMFILTER(布隆过滤器) 布隆过滤器 可以判断数据不存在，当判断结果存在时，数据可能真的存在，也可能不存在。可选的值有 三个 NONE, ROW (default), ROWCOL。
当开启 布隆过滤器 时，可以判断要查询的数据不存在在表中，从而避免查表。
行级（ROW）布隆过滤器在数据块里检查特定行键是否不存在，列标识符级（ROWCOL）布隆过滤器检查行和列标识符联合体是否不存在。ROWCOL布隆过滤器的开销高于ROW布隆过滤器。
VERSIONS(Cell数据版本) 0.96版本默认是3个， 0.98版本之后是1， 要根据业务来划分，版本是历史记录，版本增多意味空间消耗。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Core/Filter/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Core/Filter/</guid>
      <description>HBase 内置过滤器简介 HBase 的过滤器可以让我们在查询中添加更多的限制条件 来减少查询得到的数据量，从而帮助用户提高处理表数据的效率。 所有的过滤器都在服务端生效，使被过滤掉的数据不会被传送到客户端。
Filter 的继承结构  Filter  FilterBase  CompareFilter  RowFilter FamilyFilter QualifierFilter ValueFilter DependentColumnFilter  SingleColumnValueFilter  SingleColumnValueExcludeFilter  PrefixFilter PageFilter (*.fiter) KeyOnlyFilter FirstKeyOnlyFilter  FirstKeyValueMatchingQualifiersFilter  InclusiveStopFilter TimestampsFilter ColumnCountGetFilter ColumnPaginationFilter ColumnPrefixFilter RandomRowFilter ColumnRangeFilter MultipleColumnPrefixFilter MultiRowRangeFilter FuzzyRowFilter SkipFilter WhileMatchFilter  FilterList FilterWrapper   CompareFilter CompareFilter 返回匹配的行。
构造函数：
public CompareFilter(final CompareOp compareOp, final ByteArrayComparable comparator) { this.compareOp = compareOp; this.comparator = comparator; } 比较运算符：</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Core/Port/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Core/Port/</guid>
      <description>常用端口    端口 描述       2181 Zookeeper 端口           8080 HBase REST Port hbase.rest.port    16000 HBase Master hbase.master.port 1.0 之前 60000   16010 HBase Master Web UI port hbase.master.info.port 1.0 之前 60010   16020 HBase RegionServer Port hbase.regionserver.port 1.0 之前 60020   16030 HBase RegionServer Web UI port hbase.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Core/RowKey/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Core/RowKey/</guid>
      <description>Rowkey 设计  Rowkey 是一段二进制码流，最大长度为64KB Rowkey 以字典顺序排序，其方法是，按照字母顺序，或者数字小大顺序，由小到大的形成序列  Rowkey：123,321,2 顺序为: 123,2,321  查找数据的时候，先查找 Rowkey 所在的 Region，然后将求路由到该 Region 获取数据 按单个 Rowkey 检索的效率是很高的，耗时在1毫秒以下  设计原则 避免热点 避免热点首先要了解 Rowkey的排序规则 和 分区分类原理
 RowKey 按照 字典顺序 从小到大，如： 1, 12, 27, 3, 4, 66 如果没有预分区的话，刚开始所有的数据落在一个分区，当分区达到一定的阀值开始分裂，以上数据可能会分裂成 1, 12, 27 和 3, 4, 66 两个分区，每个分区记录 StartKey 和 EndKey， 多个分区会落在不同的机器上，避免热点的目的是为了利用集群的能力 和 减少分裂的次数，而不是操作都落在一台机器上  可以让头几位尽量是随机的而不是规律的产生，从而避免热点，大概有一下几种场景
 自增序列、时间戳 等自增序列  产生的数据类似于 11,12,13,14,15,16 ，假如现在有两个分区 [0,14..): 11,12,13 [14..,无穷):14,15,16 新生成 19,20,21,22 都会落在第二个分区 对于自增序列，可以通过转置的方式 比如对以上序列转置后变为，11,21,31,41,51,61 [0,4.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Install/Properties/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Install/Properties/</guid>
      <description>HBase 配置简介 获取 HBase 可配置的选项通常有以下方法：
 org.apache.hadoop.hbase.HConstants 常量类 hbase-common-x.x.x.jar 根目录下的 hbase-default.xml 配置文件 HMaster Web UI Configuration: http://localhost:16010/conf  Core / Install 以下是让 HBase 启动和运行的重要配置
hbase.tmp.dir 本地文件系统上的临时目录
默认 ${java.io.tmpdir}/hbase-${user.name}（/tmp/hbase-${user.name}）, 系统重启会自动清除
hbase.rootdir HBase 的数据保存目录。 如果是本地文件系统，必须是全路径；如果是 HDFS hdfs://namenode.example.org:9000/hbase
默认 ${hbase.tmp.dir}/hbase
hbase.fs.tmp.dir 默认文件系统（HDFS） 上用于暂存临时数据的目录
默认 /user/${user.name}/hbase-staging
hbase.bulkload.staging.dir 默认文件系统（HDFS）中的暂存批量加载临时数据目录
默认 ${hbase.fs.tmp.dir}
hbase.cluster.distributed 是否在集群模式下运行。 独立模式下的值为false，分布式模式下为true。 如果为false，将在一个JVM中一起运行所有HBase和ZooKeeper守护进程
默认 false
hbase.zookeeper.quorum 用逗号分隔的 ZooKeeper 服务器的列表。 例如host1.mydomain.com，host2.mydomain.com，host3.mydomain.com。 默认情况下，独立模式和伪分布式模式 下为localhost。 对于完全分布式模式，应该将其设置为ZooKeeper服务器的完整列表。 如果对hbase-env.sh中HBASE_MANAGES_ZK的设为true，HBase 会把 ZooKeeper 作为群集的一部分 启动（/停止）。 在客户端，常与hbase.zookeeper.clientPort（Zookeeper 端口）配置放在一起使用，并将其作为connectString参数传递给zookeeper构造函数
默认 localhost</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Install/Stand-Alone-By-Docker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Install/Stand-Alone-By-Docker/</guid>
      <description>Docker 安装 HBase  端口描述详见 Port
可选
-p 8084:8080 -p 8085:8085 -p 9090:9090 -p 9095:9095  $ docker run -d \  -p 2181:2181 \  -p 8084:8080 \  -p 8085:8085 \  -p 16000:16000 \  -p 16010:16010 \  -p 16020:16020 \  -p 16030:16030 \  --name hbase \  harisekhon/hbase # 启动 HBase REST API $ docker exec -it hbase bash # 不加端口的情况下，端口默认为8080 $$ hbase-daemon.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Install/Stand-Alone-CDH-Docker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Install/Stand-Alone-CDH-Docker/</guid>
      <description>Docker 搭建单机 CDH 环境   QuickStarts for CDH 5.13 官方下载地址
 Cloudera Docker Container 官方文档
 cloudera/quickstart 仓库
   使用 Docker 安装   MAC 设置 Docker 内存 端口描述详见 Port   # 镜像有 5G， 下载比较慢 # wget https://downloads.cloudera.com/demo_vm/docker/cloudera-quickstart-vm-5.13.0-0-beta-docker.tar.gz ᐅ docker pull cloudera/quickstart # 启动容器 ᐅ docker run -d \ 	--hostname=quickstart.cloudera \ 	--privileged=true \ 	--name=cdh-5.13 \ 	-p 81:80 \ 	-p 2181:2181 \ 	-p 9092:9092 \ 	-p 60010:60010 \ 	-p 60000:60000 \ 	-p 8888:8888 \ 	-p 7180:7180 \ 	cloudera/quickstart bash -c &amp;#34;while true; do echo noting; sleep 1; done&amp;#34; # /usr/bin/docker-quickstart # 进入容器 ᐅ docker exec -it cdh-5.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/Install/Stand-Alone-Local-File/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/Install/Stand-Alone-Local-File/</guid>
      <description>单机本地文件系统 # 下载 wget http://mirrors.hust.edu.cn/apache/hbase/stable/hbase-1.2.6-bin.tar.gz vim hbase-1.2.6/conf/hbase-site.xml # 新增 # &amp;lt;property&amp;gt; # &amp;lt;name&amp;gt;hbase.rootdir&amp;lt;/name&amp;gt; # &amp;lt;value&amp;gt;file:///opt/data/hbase&amp;lt;/value&amp;gt; # &amp;lt;/property&amp;gt; # # 如果 hbase-env.sh 中 export HBASE_MANAGES_ZK=true 设置true，最好指定 Zookeeper 的数据路劲 # &amp;lt;property&amp;gt; # &amp;lt;name&amp;gt;hbase.zookeeper.property.dataDir&amp;lt;/name&amp;gt; # &amp;lt;value&amp;gt;/opt/data/hbase-zookeeper&amp;lt;/value&amp;gt; # &amp;lt;/property&amp;gt; # # 如果 hbase-env.sh 中 export HBASE_MANAGES_ZK=false 设置false，需要再加入以下配置 # &amp;lt;property&amp;gt; # &amp;lt;name&amp;gt;hbase.cluster.distributed&amp;lt;/name&amp;gt; # &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt; # &amp;lt;/property&amp;gt; vim hbase-1.2.6/conf/hbase-env.sh # 修改 JAVA_HOME， 去掉前面的 #， # export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/ # 修改 HBASE_CLASSPATH ，去掉前面的 # # export HBASE_CLASSPATH=/opt/websuite/hbase-1.2.6 # 默认是 true ，如果使用 外部 Zookeeper ，设置为 false 即可 # export HBASE_MANAGES_ZK=true # 启动 Hbase .</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hello-world-example.github.io/HBase/docs/todo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hello-world-example.github.io/HBase/docs/todo/</guid>
      <description>org.apache.hadoop.hbase.io.hfile.HFile ./hbase org.apache.hadoop.hbase.io.hfile.HFile -m -f /hbase-sc/data/news/NewsClickFeedback/627b1d95153d4157351b65135ab701a3/Toutiao/011b41375e584530a24a3a203b9ce1a3
Block index size as per heapsize: 704
reader=/hbase-sc/data/news/NewsClickFeedback/627b1d95153d4157351b65135ab701a3/Toutiao/011b41375e584530a24a3a203b9ce1a3,
compression=snappy, cacheConf=CacheConfig:disabled, firstKey=a0000000be3d27a5a11d203f798781a9/Toutiao:ClickViewTS/1465783628056/Put, lastKey=a80072cbf409d04542f272446d4b65a4/Toutiao:ClickViewTS/1465776679416/Put, avgKeyLen=62, avgValueLen=93, entries=6451829, length=698454846  hbase org.apache.hadoop.hbase.mapreduce.Driver &amp;hellip;&amp;hellip;</description>
    </item>
    
  </channel>
</rss>